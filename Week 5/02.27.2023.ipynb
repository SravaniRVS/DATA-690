{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1e6ce3",
   "metadata": {},
   "source": [
    "# DATA 690\n",
    "Week 5\n",
    "## Introduction to Pandas\n",
    "\n",
    "### Why should you care?\n",
    "\n",
    "The Pandas library allows us to easily analyze data in Python in a way that is similar to *R*. The Pandas library introduces two new data structures that are optimized for data analysis: the `Series` and `DataFrame`. Mastering the use of `Series` and `DataFrame` objects and their methods will help you to effectively and elegantly perform a wide variety of data analysis tasks.\n",
    "\n",
    "   * **Series** - A single dimension of data. It is analogous to a single column of data or a one dimensional array. (Analogous to a vector in R.)\n",
    "   * **DataFrame** - A two-dimensional data structure that looks like any other rectangular table of data you have seen with rows and columns. Every column in a pandas DataFrame is a Series. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98864bd",
   "metadata": {},
   "source": [
    "## Import Pandas\n",
    "\n",
    "To be able to use Pandas for data analysis, we first need to import it. By convention, Pandas is usually imported with the alias `pd` as `import pandas as pd`. Recall, that this allows us to use a function `func()` from the Pandas library using the syntax: `pd.func()` or by calling a Pandas function on a Pandas object (a Series or a DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8989b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importing pandas as pd is standard.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Python magic to allow plots to display in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed4e65",
   "metadata": {},
   "source": [
    "## Pandas Series\n",
    "\n",
    "A Pandas `Series` is a special type of list that is optimized for data analysis. A Pandas `Series` object is very similar a list but:\n",
    "\n",
    "+ it can only hold data of one type\n",
    "+ always has an *index* attached to each observation\n",
    "+ is optimized for data analysis tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba410f",
   "metadata": {},
   "source": [
    "### Creating a Series\n",
    "\n",
    "You can convert a list,numpy array, or dictionary to a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2791007",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['a','b','c']\n",
    "my_list = [10,20,30]\n",
    "arr = np.array([10,20,30])\n",
    "d = {'a':10,'b':20,'c':30}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f3ccd",
   "metadata": {},
   "source": [
    "** Using Lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c3e826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    20\n",
       "2    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(data=my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d9622b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(data=my_list, index = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0407e5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(my_list, labels) # no need to mention data and index, but better to include for good understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d789b0",
   "metadata": {},
   "source": [
    "** NumPy Arrays **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9fa855a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    20\n",
       "2    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcec184d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(arr, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25394f7b",
   "metadata": {},
   "source": [
    "** Dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c339ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8ac9a",
   "metadata": {},
   "source": [
    "### What is an Index?\n",
    "\n",
    "One difference between a `list` and a Pandas `Series` is the presence of an **index**. An index is a convenient label that helps to identify observations in the data.\n",
    "\n",
    "In the output of the cell above, you see the numbers 0, 1, 2, 3, 4 printed out on the left. These numbers are the default integer based index called a *RangeIndex*. All Pandas objects must have an index, and if an index is not provided, the default index (RangeIndex) will be used.\n",
    "\n",
    "We can access the index via the `.index` attribute. (Recall, everything in Python is an *object*. Objects have properties called *attributes* and tasks that they know how to accomplish called *methods*.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f79be511",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=3, step=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the index \n",
    "\n",
    "ser1 = pd.Series(data=my_list)\n",
    "ser1.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2259bebf",
   "metadata": {},
   "source": [
    "### What do we mean by a more 'meaningful' index?\n",
    "\n",
    "With the height data available for each of my 5 friends, the height of each of my friends (in inches) is the data I want to use to extract insights. My friends names, however, are not useful data to perform analysis on, their names are just convenient *labels* that help me understand who the measurements refer to.\n",
    "\n",
    "We could:\n",
    "\n",
    "+ refer to each friend by name (by using meaningful Index): Matt, Sam, Peter,...\n",
    "+ refer to friend by integer location (using the default RangeIndex): 0th Friend, 1st Friend, 2nd Friend...\n",
    "\n",
    "It is never **required** to choose an index, you can complete all of your analysis with just the default *RangeIndex*. Setting a column to be an index can help identify the rows such as with the friends names above. It is best to choose columns that are unique and descriptive. Python does not enforce the uniqueness of the index but it does help when needing to identify one particular row.\n",
    "\n",
    "To add a more meaningful index when creating a Pandas series, pass a list containing the index values via the `index` parameter when creating the Series.\n",
    "\n",
    "`pd.Series(<values_list>, index = <index_list>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14c99253",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Friends data as lists\n",
    "\n",
    "heights = [72, 68, 76, 77, 80]\n",
    "names = ['Matt', 'Sam', 'Peter', 'Ana', 'Darla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a02ca1a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matt     72\n",
       "Sam      68\n",
       "Peter    76\n",
       "Ana      77\n",
       "Darla    80\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Series with a meaningful index\n",
    "\n",
    "friends_data = pd.Series(index = names,data = heights)\n",
    "friends_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd6f1d5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Matt', 'Sam', 'Peter', 'Ana', 'Darla'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the index of friends_data\n",
    "friends_data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146c820",
   "metadata": {},
   "source": [
    "### Creating Pandas Series using a dictionary\n",
    "\n",
    "Recall, a *dictionary* contains *key/value* pairs where the *key* is a meaningful, unique label for the data contained in the values. Doesn't that sound similar to our description of a meaningful *index*?\n",
    "\n",
    "Passing a *dictionary* to the Pandas `Series()` constructor automatically uses the *keys* as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "886f69db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matt     72\n",
       "Sam      68\n",
       "Peter    76\n",
       "Ana      77\n",
       "Darla    80\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Friends data as a dictionary\n",
    "friends_dict = {'Matt': 72, 'Sam': 68, 'Peter': 76, 'Ana': 77, 'Darla': 80}\n",
    "\n",
    "# Create Pandas Series\n",
    "friends_data2 = pd.Series(friends_dict)\n",
    "friends_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ab53f",
   "metadata": {},
   "source": [
    "### Why is the index useful?\n",
    "\n",
    "For now, it is best to think of the index as a meaningful label. In fact, with an index we can extract data from our Series using either the index location (`my_series[<rownumber>]`) or by index label (`my_series[<label>]`). In this respect, a Pandas `Series` is a hybrid of a list and a dictionary as we can refer to values in the `Series` using both approaches.\n",
    "\n",
    "The Pandas index is very powerful but can be confusing when encountering it for the first time.\n",
    "\n",
    "Note: there is no real equivalent to the Pandas index in R. In Base R, there are rownames, but R does not make use of the rownames in way that the Pandas library does. Further, the tidyverse paradigm explicitly does not use the R rownames at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5f077",
   "metadata": {},
   "source": [
    "### How can we extract data from a Series?\n",
    "\n",
    "A wonderful property of Pandas Series (and DataFrames) is that we can refer to data values by *label* using the index labels and the `.loc()` function AND/OR by *integer index* location using the `.iloc()` function since Series and DataFrames are ordered (meaning they always have an implicit row number based index). We will learn more about these two functions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d2a0712",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the height of Peter using the named index\n",
    "\n",
    "friends_data2['Peter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e3548c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends_data.loc['Peter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b489da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract the height of Peter using the integer index location. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d547e8",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "\n",
    "One difference between a Pandas `Series` and a `list` is that a Series can only contain data of one **data type**. The data types in Pandas are from the **Numpy** library that allows for *numerical computing* in Python. These data types are very similar to the base Python data types that we have already encountered but they are optimized for data analysis. For all practical purposes, what you already know about the base Python data types carries over to the Pandas data types.\n",
    "\n",
    "The main data types available are:\n",
    "\n",
    "+ boolean (bool): True/False\n",
    "+ integer (int64): whole numbers, no decimals\n",
    "+ float (float64): numbers with decimals\n",
    "+ object: mainly strings\n",
    "+ datetime: (datetime64[ns]): a timestamp, a specific moment in time\n",
    "\n",
    "There other data types available and we will cover them as they are needed. These include:\n",
    "\n",
    "+ category\n",
    "+ timedelta (a specific amount of time, ex. time elapsed between two timestamps) \n",
    "+ period (a specific time period, ex. Financial data is often reported by Quarter: Q1, Q2, Q3, Q4)\n",
    "\n",
    "The *object* data type is a bit confusing. Each value in an object column can be any Python object. But, nearly all of the time, object data type columns contain strings. They can contain any other Python object such as integers, floats, or even complex types such as lists or dictionaries. There is no specific data type for strings as there are in most other data processing packages. When you see that object is the data type, you should assume you have a string column. \n",
    "\n",
    "Note: If there is at least one observation in a column of data that contains a string, the entire column will be cast a *object* type.\n",
    "\n",
    "You can find out what the data type is by using the `.dtypes` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29746a25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What type of data is friends_data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173d72d",
   "metadata": {},
   "source": [
    "## Pandas DataFrame\n",
    "\n",
    "A Pandas DataFrame is a collection of columns of data (each are Pandas Series) that share a common index to identify the rows and a column index to identify columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c283dffb",
   "metadata": {},
   "source": [
    "### How can we construct a Pandas DataFrame?\n",
    "\n",
    "Since a `DataFrame` is really just a collection of `Series` that share a common index, if we have data stored in multiple lists or a dictionary, we can pass the object to the `pd.DataFrame()` constructor. There are many different ways the data can be represented to create a `DataFrame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378954d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe from the friends data\n",
    "\n",
    "#friends_dict = {'Matt': 72, 'Sam': 68, 'Peter': 76, 'Ana': 77, 'Darla': 80}\n",
    "\n",
    "friends_data = {'names':['Matt', 'Sam', 'Peter', 'Ana', 'Darla'],\n",
    "                'heights': [72, 68, 76, 77, 80],\n",
    "                'eye_color':['brown', 'blue', 'green', 'brown', 'green']  \n",
    "}\n",
    "friends_df = pd.DataFrame(friends_data)\n",
    "friends_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73982a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How do we know that this is really a Pandas DataFrame?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caadb56",
   "metadata": {},
   "source": [
    "Like before, we have a choice to make about the index. In the output above, we see that the default *RangeIndex* is being used. If we want to make the `names` the index, we can use the `.set_index()` method for DataFrames. As before with Series, this allows us to refer to the data by label or integer index position.\n",
    "\n",
    "To change the index, use the `.set_index(<col_to_become_index>, inplace = True)` method. When replacing the default index, the column that becomes the index is removed from the data by default.\n",
    "\n",
    "If the default integer *RangeIndex* is desired, use the `.reset_index(inplace = True)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d1fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to be names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information for Peter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb6b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e18a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594ede3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reset the index back to RangeIndex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b60c54",
   "metadata": {},
   "source": [
    "# Missing Data\n",
    "\n",
    "Let's show a few convenient methods to deal with Missing Data in pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A':[1,2,np.nan],\n",
    "                  'B':[5,np.nan,np.nan],\n",
    "                  'C':[1,2,3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36958ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133be2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41801024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d328c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7417e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6455813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da4141b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How do we read in data from a file?\n",
    "\n",
    "Typically, we read data in from a file, url, or database. The most common file format, `.csv`, can easily be read-in using the Pandas `.read_csv()` function. This function will automatically create a DataFrame for us. Among the many useful arguments that `.read_csv()` accepts, you will find it particularly useful to specify the index and how to properly cast columns to the correct data type. We will explore these features at a later time.\n",
    "\n",
    "For practice, we will read in the `mtcars` data provided by Motor Trend to get some practice with DataFrames.\n",
    "    \n",
    "| Name: | Description: |\n",
    "|:-------|:--------------|\n",
    "| make  | Car Manufacturer |\n",
    "| model | Car Model    |\n",
    "| type  | Model Type: Sedan, SUV, Sports Car, Wagon, Truck, Hybrid |\n",
    "| origin | Country where car manufactured |\n",
    "| drivetrain | Drivetrain type: Front, Rear, All Wheel Drive |\n",
    "| msrp | Manufacturers Suggested Retail Price in US dollars |\n",
    "| invoice | Actual Selling Price in US dollars |\n",
    "| engine  |\tEngine Size (L) |\n",
    "| cyl   | Number of cylinders |\n",
    "| hp    | Gross horsepower |\n",
    "| mpg_city | Miles/(US) gallon in City|\n",
    "| mpg_hwg | Miles/(US) gallon on Highway|\n",
    "| wt    | Weight (1000 lbs) |\n",
    "| wheelbase | Distance between the centers of the front and rear wheels (in) |\n",
    "| length | Length of vehicle (in) |\n",
    "| domestic | Indicator variable: 1 = domestic, 0 = foreign |\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b84a1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import mtcars data\n",
    "\n",
    "\n",
    "# What type of object is our data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a4bcb",
   "metadata": {},
   "source": [
    "Now that the data has been read-in and the `DataFrame` constructed. Let's investigate the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5560509",
   "metadata": {},
   "source": [
    "### Extracting DataFrame Components\n",
    "\n",
    "The diagram above shows the a `DataFrame` consists of a *row index* identifying the observations of the data, a *column index* containing the column names, and the *data* as Pandas `Series` objects. Let's make sure we can extract these elements. \n",
    "\n",
    "+ We have already encountered the `.index` attribute with Series objects, but all DataFrames also have this attribute.\n",
    "\n",
    "+ The *column index* is available via the `.columns` attribute. Recall, an index is just a *label* so it makes sense to think of the column names as a type of index.\n",
    "\n",
    "+ Any column of data, a Series, can be extracted by *label* as `df['colname']`\n",
    "\n",
    "Let's try these out on the `mtcars` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c44422",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract the index - identify each row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd1b2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract the column names - identify each column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e9245",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract the mpg column as a series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd499ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03effee",
   "metadata": {},
   "source": [
    "#### Alternate method for accessing a column of data as a Series - Caution!\n",
    "\n",
    "Another common way to access a column from a data frame is to use dot notation. For example, we could select the `mpg_city` column from the `mtcars` data set by typing `mtcars.mpg_city`. This notation is very common and can be convenient, however, there are limitations to this method and for that reason it is best NOT to get in the habit of using this notation when first learning to work with Pandas.\n",
    "\n",
    "The dot notation does not work when:\n",
    "\n",
    "+ the variable name contains a space (For example: if the column name was `mpg city`)\n",
    "+ the variable name is the same as an attribute or python function (For example: if column name was 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1e649b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract the mpg column as a series using dot notation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca1460",
   "metadata": {},
   "source": [
    "## What do we do first? Data Analysis Workflow\n",
    "\n",
    "When we get a new data set, we want to:\n",
    "1. Inspect a few rows of the data to get a feel for what the data looks like. Rename columns as necessary to make data easier to work with.\n",
    "1. Investigate how many rows and columns are in the data\n",
    "1. Determine what types of data are present in the columns. Make sure that the variable types are what we expected. If not, make the appropriate type conversion. Create new variables as needed.\n",
    "1. Determine if there are missing values in the data.\n",
    "1. Set a meaningful index, change an index, or reset the index to the default `RangeIndex`\n",
    "1. Write a DataFrame or Series to file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352fef49",
   "metadata": {},
   "source": [
    "### Step 1: Inspect a few rows of the data\n",
    "\n",
    "#### Observations\n",
    "\n",
    "Recall that **observations** are the rows in a tabular data set. It is important to think about what each row represents, or the **unit of observation**, before starting a data analysis. In the `mtcars` DataFrame, the unit of observation is a specific model of car. This makes it easy to answer questions about cars (e.g., \"What percentage of cars get more than 20 MPG?\") but harder to answer questions about cars from a particular country (e.g., \"What percentage of Toyotas have a fuel efficiency above 20 MPG in the city?\")\n",
    "\n",
    "There is no single \"best\" representation of the data. The right representation depends on the question you are trying to answer: if you are studying single cars, then you might want the unit of observation to be a car, but if you need to know about fuel efficiency by car maker, then you might prefer that it be car manufacturer. No matter which representation you choose, it is important to be conscious of the unit of observation.\n",
    "\n",
    "The three main ways to quickly inspect a few observations/rows of data:\n",
    "+ `df.head(n)`\n",
    "+ `df.tail(n)`\n",
    "+ `df.sample(n)`\n",
    "\n",
    "The *n* parameter has a default value of 5.\n",
    "\n",
    "Once a few rows of data are printed, make sure you can identify the type of observational unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b51fbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspect the first five rows of data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e69b94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspect the last few rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89504595",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspect a few random rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac74b9c",
   "metadata": {},
   "source": [
    "#### Renaming columns\n",
    "\n",
    "We could keep referring to the *data description* above where the meaning of the data in the columns is explained. However, this can be time-consuming and confusing. Oftentimes it is a good idea to give columns with unclear meanings a better name. We can do this with the `.rename()` function and specifying the `columns` argument. All that is necessary to use this function is to create a dictionary with the keys as the old names to replace and the values the new names we want to use and pass this argument to `columns`.\n",
    "\n",
    "Which columns in the `mtcars` data could use better names?\n",
    "\n",
    "+ The `wt` column tells us about the weight of the car. Maybe it would be better to just rename this column `weight`.\n",
    "+ The `engine` column tells us about the size (displacement) of the engine. Maybe a better name would be `engine_size`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0e61f4",
   "metadata": {},
   "source": [
    "### Step 2: How many rows and columns are present in the data?\n",
    "\n",
    "All DataFrames have a shape **attribute** that we can access as `df.shape`. \n",
    "\n",
    "The shape of DataFrame will be returned as a tuple of the form: `(number of rows, number of columns)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb05dd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What is the size of data? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is the particular data structure for shape used?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1424256",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How many rows are there? Extract elements from a tuple using []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc31c84a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How many columns are there?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de934790",
   "metadata": {},
   "source": [
    "### Step 3: Determine what types of data are available in each column\n",
    "\n",
    "#### Data Types\n",
    "\n",
    "All Dataframes have a dtypes **attribute** that we can access as ```df.dtypes```.\n",
    "\n",
    "A Pandas Series will be returned with the data *type* of each column from our data and with the column names as the *index*. Since Python returns a Series object, the data type for a specific feature/column from the data can be extracted by label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee9654",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find the data types for each column in the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57448297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How can we extract the data type of the `weight` columns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5950ff",
   "metadata": {},
   "source": [
    "### Variable Types\n",
    "\n",
    "Variables that can be measured on a numeric scale are called **quantitative variables**. Just because a variable happens to contain numbers does not necessarily make it \"quantitative\". For example, consider the variable `domestic` data set. Each car is either foreign or domestic. This data set happens to use 1 for \"domestic\" and 0 for \"foreign\", but these numbers do not reflect an underlying numeric scale.\n",
    "\n",
    "Variables that are not quantitative but take on a limited set of values are called **categorical variables**. Although categories are usually non-numeric, they are sometimes given numeric values like the `domestic` variable. With a categorical variable, one common analysis question is, \"How many observations are there in each category?\".\n",
    "\n",
    "Some variables do not fit neatly into either category. For example, the variable `model` in the `mtcars` data set is obviously not quantitative, but it is not categorical either because it does not take on a limited set of values. Every car has a different name, so it does not make sense to analyze the frequencies of different model names, as one might do with a categorical variable. We will group variables like `model`, that are neither quantitative nor categorical, into an \"other\" category. These `other` type variables are often a good choice for the **index**, especially if they have a unique value for each row.\n",
    "\n",
    "Some variables, like `cyl`, the number of cylinders in the engine, can be thought of as either **quantitative** or **categorical** depending on what you are trying to do.\n",
    "\n",
    "+ Suppose we wanted to calculate the displacement per cylinder or investigate the association between fuel consumption and the number of cylinders a car has. Here we treat `cyl` as a number.\n",
    "+ Suppose we wanted compare the fuel efficiency of cars by the number of cylinders they have. In this situation, we are treating the number of cylinders as a grouping variable, meaning that we are treating it like a **categorical** variable.\n",
    "\n",
    "Every variable can be classified into one of these three **types**: quantitative, categorical, or other. The type of the variable often dictates the kind of analysis we do and the kind of visualizations we make, as we will see later in this chapter. \n",
    "\n",
    "#### Adjusting Data Types\n",
    "\n",
    "The `domestic` column contains information about whether or not a car is foreign or domestic. The data type for the `domestic` column is listed as `int64`. Is this the best data type for this column? Probably not.\n",
    "\n",
    "We have at least two options.\n",
    "\n",
    "1. We can change the data type to object using the ```.astype()``` method\n",
    "1. We can recode the column using the ```.replace()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54dd4c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Option 1: Change the data type for the column to 'object' using astype()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ead78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data type has changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1436e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, when printing out some values, Pandas tells us the data type is \n",
    "# object but the values are not properly quoted like strings!\n",
    "# Be very aware of the data types!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90af968",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Option 2: Recode the column using the .replace method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180d7e4",
   "metadata": {},
   "source": [
    "What about the `cyl` column? This represents the number of cylinders the car has. The number of cylinders is an integer, but would we use it like a normal integer in a data analysis context?\n",
    "\n",
    "Let's create a new column in our data set called `cat_cyl` which will be a categorical representation of the `cyl` variable. This way, we can be explicit when exploring the different ways we might choose to use this variable. Note: it is not necessary to create a categorical representation of the `cyl` variable, we are just doing it for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c0a0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recode the cyl column using the .replace method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93635f46",
   "metadata": {},
   "source": [
    "#### Creating a new variable as a function of the others\n",
    "\n",
    "Suppose that instead of just recoding a variable, we wanted to create a new column as a function of the others? \n",
    "\n",
    "Let's create a new variable in our data set that represented the engine size (displacement) per cylinder `disp_per_cyl`?\n",
    "\n",
    "We can create new columns by assignment exactly as we did with dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af61f2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4125c02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a new column called 'disp_per_cyl'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd34cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round `disp_per_cyl` to 2 decimal places\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94ad1a",
   "metadata": {},
   "source": [
    "Let's create a column called `diff_price` which is the difference between the `msrp` price and the actual selling price `invoice'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e04c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diff_price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addb912d",
   "metadata": {},
   "source": [
    "### Step 4: Determine if there are missing data\n",
    "\n",
    "We can apply the `.count()` method to our DataFrame and Pandas will return a Series with the number of non-null values in each column. \n",
    "\n",
    "Alternatively, we can apply the ```.isnull()``` method to a series or a Dataframe and python will return a boolean representation where a ```True``` indicates the value is missing or NaN. If we use **method chaining** and apply the ```sum()``` function, we will obtain a Pandas Series containing the number of missing observations in each column.\n",
    "\n",
    "(We will cover functions like ```sum()``` more later in the course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many non-null values are in each column?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51161768",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use the .isnull().sum() to determine if there are missing data\n",
    "# Are there any missing data in the mtcars dataframe?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11985534",
   "metadata": {},
   "source": [
    "It looks like there are two observations in the data containing missing values. The missing data was in the `cyl` column and since we created two new columns that are functions of `cyl` then these columns have missing values as well. In the next section we will learn how to identify what cars have missing data for the `cyl` column and then we can do some detective work to figure out why the data is missing.\n",
    "\n",
    "Most real world data contains missing data. Methods to deal with missing data will be discussed later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326311c",
   "metadata": {},
   "source": [
    "### Quick look at Dataframe structure\n",
    "\n",
    "We can also use the ```df.info()``` data frame **method**. This method will print out useful information about our data frame structure and its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91fab55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use the .info() method to print out useful information about the data frame contents\n",
    "\n",
    "\n",
    "# to get exact memory usage, memory_usage = 'deep'\n",
    "#mtcars.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a20001c",
   "metadata": {},
   "source": [
    "#### What does `info()` tell us about the mtcars data?\n",
    "\n",
    "Based on the ```mtcars.info()``` output, what information can we glean?\n",
    "\n",
    "1. data structure type - `Pandas DataFrame`\n",
    "1. Index type\n",
    "1. number of columns\n",
    "1. column names, number of non-null entries, column type\n",
    "1. summary of data types available in data\n",
    "1. memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606df05f",
   "metadata": {},
   "source": [
    "### Step 5: Manipulating the Index\n",
    "\n",
    "#### How can we change the index?\n",
    "\n",
    "The index can be used to our advantage if we choose a meaningful index. A meaningful index is best if it is unique and descriptive of the observations in the data.\n",
    "\n",
    "For the ```mtcars``` data, the ```model``` is the type of car which is unique and descriptive of what the observations in each row represent. Note, this column is not all that useful as a column of data, there is no real analysis that we would do with it! These two properties make `model` a great choice of index.\n",
    "\n",
    "Let's use the `.set_index(col_to_become_index, inplace = True)` method to set a meaningful index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb26cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d17f569",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make the model the index for mtcars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dce045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What has changed about the shape attribute?\n",
    "# Note that the number of columns is reduced\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf6168",
   "metadata": {},
   "source": [
    "#### Important Note\n",
    "\n",
    "These commands should only be run once. If you try to run them a second time, you will get an error. Create a cell below and give it a try it! The reason for the error is: after the command is executed the first time, `model` is no longer a column in `mtcars`, since it is now in the index. When the command is run again, Pandas will try (and fail) to find a column called `model`. \n",
    "\n",
    "The interactivity of Jupyter notebooks allows us to see the results of our code immediately, but it makes it easy to lose track of the state, especially if you run a cell twice or out of order. Jupyter notebooks are designed to be run from beginning to end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6181d7f",
   "metadata": {},
   "source": [
    "#### How can we tell what the index is?\n",
    "\n",
    "Glance at the data above. Notice:\n",
    "\n",
    "+ the index column is now in bold\n",
    "+ the column name for the index column is now lower than the other column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629070c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# re-investigate the index, what is different about the index now than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b15587",
   "metadata": {},
   "source": [
    "#### Reseting the Index\n",
    "\n",
    "If wanting to revert to the default integer *RangeIndex*, use the `.reset_index(inplace = True)` method and the `model` column is added back to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1fae0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How can we put the index back as a column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ac7f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What has changed again about the shape attribute?\n",
    "# Note the model has been added back to the DataFrame as a column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccafd548",
   "metadata": {},
   "source": [
    "#### Setting the Index using `pd.read_csv()`\n",
    "\n",
    "The `pd.read_csv()` method has many handy arguments for processing & cleaning data while loading the data. When working with familiar data, processing the data when reading the data in can save a lot of time. If you know that a particular column of data would make a good index, use the `index_col = '<col name>'` argument to set the index automatically. We will use this method in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96511d71",
   "metadata": {},
   "source": [
    "### Step 6:  Writing Data to File\n",
    "\n",
    "We just spent a lot of time making the `mtcars` data in a format that will be useful to analyze. In order to read the data into another notebook, we probably should write the data to file. This can be accomplished using the Pandas `.to_csv()` function. There are many arguments that we could specify, but for now we need only specify the file path/name. Let's store it in our **data** folder.\n",
    "\n",
    "When the index is a `RangeIndex`, we do not want Pandas to store the index as a variable, which by default Pandas will do. We can tell Pandas not to store the index as a variable by including the argument `index = False` in the `to_csv()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef759c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to file called `cars_clean`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c46b74",
   "metadata": {},
   "source": [
    "## Selecting Subsets of data using Pandas\n",
    "\n",
    "### Why should you care?\n",
    "\n",
    "When analyzing data we often want to focus on various interesting subsets of the data. To be able to effectively analyze data using pandas, we need to know how to quickly and efficiently find and extract observations matching various criteria.\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives:\n",
    "\n",
    "By the end of this tutorial, you should be able to:\n",
    "\n",
    "+ Use the three indexers `[ ]`, `loc`, and `iloc` to select subsets of data\n",
    "+ Understand Boolean Indexing or Boolean Selection for the selection of a subset of a Series/DataFrame based on the **values** themselves and not the row/column labels or integer location\n",
    "+ Effectively use Boolean selection to filter observations\n",
    "+ Drop observations/columns using the `.drop()` method\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e84d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned mtcars data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7f4e6",
   "metadata": {},
   "source": [
    "We will use in our modified `cars` data from the previous section. *Notice that by including `index_col = 'model'` the index was set for us automatically*\n",
    "    \n",
    "| Name: | Description: |\n",
    "|:-------|:--------------|\n",
    "| make  | Car Manufacturer |\n",
    "| model | Car Model    |\n",
    "| type  | Model Type: Sedan, SUV, Sports Car, Wagon, Truck, Hybrid |\n",
    "| origin | Country where car manufactured |\n",
    "| drivetrain | Drivetrain type: Front, Rear, All Wheel Drive |\n",
    "| msrp | Manufacturers Suggested Retail Price in US dollars |\n",
    "| invoice | Actual Selling Price in US dollars |\n",
    "| engine  |\tEngine Size (L) |\n",
    "| cyl   | Number of cylinders |\n",
    "| hp    | Gross horsepower |\n",
    "| mpg_city | Miles/(US) gallon in City|\n",
    "| mpg_hwg | Miles/(US) gallon on Highway|\n",
    "| wt    | Weight (1000 lbs) |\n",
    "| wheelbase | Distance between the centers of the front and rear wheels (in) |\n",
    "| length | Length of vehicle (in) |\n",
    "| domestic | Indicator variable: 1 = domestic, 0 = foreign |\n",
    "| cat_cyl | Categorical representation of `cyl`, created in section 2.1 |\n",
    "| disp_per_cyl | Displacement per cylinder, created in section 2.1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd35486",
   "metadata": {},
   "source": [
    "## Selecting subsets of data (indexing)\n",
    "\n",
    "There are three main ways to select subsets of the data.\n",
    "\n",
    "+ `[]` is to select one or more columns of a DataFrame\n",
    "+ `loc` can select rows, columns, or rows and columns simultaneously and selects primarily by **label**\n",
    "+ `iloc` can select rows, columns, or rows and columns simultaneously and selects only by **integer location**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb37e6c",
   "metadata": {},
   "source": [
    "### Subset selection using brackets `[]` - Selecting columns\n",
    "\n",
    "You can retrieve an individual Series from a DataFrame by passing the Series name/key to the DataFrame. \n",
    "\n",
    "You can retrieve multiple columns at once by passing a list of column names in the brackets `[]`. When you do this, you actually get a new DataFrame, rather than a list of individual Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e528e1b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using with brackets notation, one set of brackets returns a Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed2b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify type is Series\n",
    "type(mtcars['mpg_city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb1f8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using with brackets notation, two sets of brackets (passing a list) returns a DataFrame\n",
    "# if grabbing more than one column, must pass a list\n",
    "\n",
    "mtcars[['mpg_city']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef6ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify type is DataFrame because a list was passed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c40865",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extracting more than one column at a time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify type is DataFrame because a list was passed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1338b70",
   "metadata": {},
   "source": [
    "### Subset selection `.iloc()`\n",
    "\n",
    "iloc - select rows and/or columns by integer location using the integer position and **slicing** syntax\n",
    "\n",
    "Using the `df.iloc[]`, we can grab subsets of data based on the integer row and column values. This method of extracting data does not rely on the `index` values but rather on the fact that Pandas objects are ordered.\n",
    "\n",
    "The *Slicing* syntax is used for both rows and columns, separated by a `,` as `df.iloc[<slice rows>, <slice cols>]`. If wanting *all* rows/columns, use `:`, telling Pandas to start at the beginning and grab everything to the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using df.iloc(), extract the value in first row and first column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12dcd17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using df.iloc(), extract the first 4 rows and the first 3 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first 4 rows across all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d417e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first three columns across all rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d0fdb",
   "metadata": {},
   "source": [
    "### Subset selection `.loc()`\n",
    "\n",
    "`.loc()` - select rows and/or columns by label\n",
    "\n",
    "Using the `df.loc[<rows>, <cols>]`, we can grab subsets of data based on their *row and col labels* as given by the `.index` and `.columns` attributes.\n",
    "\n",
    "The *Slicing* syntax is used for both rows and columns, separated by a `,` as `df.loc[<slice rows>, <slice cols>]`. When looking at the .`head()` of the `mtcars` DataFrame, we see that the Acura *MDX* is the first car in the data and the Acura *TL 4dr* is the fourth car in the data. The first three columns are `make`, `type`, and `origin`. *Slicing* works the same way as before, but now we *slice* using the labels.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View head of mtcars DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the observation for an Acura MDX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd996b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To extract the first 4 rows and 3 columns of a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00130de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract values across all labels for observations with the column label 'mpg_city'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f8a92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To extract all rows and the first 3 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab specific rows and cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638468b",
   "metadata": {},
   "source": [
    "## Boolean Subsetting with `.loc()`\n",
    "\n",
    "Oftentimes, we want to filter observations or select columns based on specific criteria. \n",
    "\n",
    "For example: \n",
    "\n",
    "+ locate all fuel efficient vehicles: `mpg_city` > 20\n",
    "+ locate all 4 cylinder, fuel efficient vehicles: `cyl` = 4 AND `mpg_city` > 20 MPG\n",
    "+ locate all cars that are either fuel efficient `mpg_city`> 20 MPG OR vehicles that have 6 cylinders\n",
    "+ locate all rows with missing values\n",
    "\n",
    "We can answer such questions by making use of a **Boolean Series**, a series of True/False values. A Boolean Series can be created by using the Python comparison operators on a *Series* selected from our data. Once we have created the desired Boolean Series, we can use it in conjunction with the `.loc()` method to return values where the Boolean Series is True. A Boolean Series used to filter a Pandas Series or DataFrame is also commonly referred to as a **Boolean Filter** or a **Boolean Mask**.\n",
    "\n",
    "To effectively use Boolean selection to filter observations, use a two-step process.\n",
    "   + First, create a **filter** - a sequence of True/False values the same length as the DataFrame/Series\n",
    "   + Second, pass this filter to one of the indexers **`[ ]`** or **`loc`**\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a8c0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# locate all fuel efficient vehicles, mpg_city > 20 MPG, create a Boolean mask\n",
    "# simply a Series where all observations meeting condition are True, else False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d56799",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create filter\n",
    "\n",
    "\n",
    "# extract rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06d31b",
   "metadata": {},
   "source": [
    "### Filtering with multiple conditions\n",
    "\n",
    "Now that we can filter based on a single condition, we can filter based on compound conditions using the (`&` = and, `|` = or, `~` = not) bitwise logical operators. The difference between the bitwise `&` operator and the Boolean operator `and` is the bitwise operator *broadcasts* to all elements in the Series whereas `and` is for evaluating the truth of a single compound Boolean expression. \n",
    "\n",
    "If we want to find all cars that have 4 cylinders AND are fuel efficient vehicles (mpg_city > 20 MPG), we need only create the two simple filters first and combine them with the logical and operator `&`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5589edb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create compound filter\n",
    "\n",
    "\n",
    "# extract rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8032b",
   "metadata": {},
   "source": [
    "Alternatively, we can create the compound filter all-at-once by wrapping each sub-filter in parentheses: `(mtcars['mpg_city'] > 20) & (mtcars['cyl'] == 4)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bdb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compound filter\n",
    "\n",
    "\n",
    "# extract rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate all cars that are either fuel efficient `mpg`> 20 MPG OR vehicles that have 6 cylinders\n",
    "\n",
    "# Create compound filter\n",
    "\n",
    "\n",
    "# extract rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23e8483",
   "metadata": {},
   "source": [
    "### Creating a Boolean Filter to Find Missing Values\n",
    "\n",
    "Recall, in the previous notebook we discovered that there were missing values in the data. We easily create a Boolean Filter by applying the Pandas method `isnull()` to a column of our DataFrame which will return `True` if the observation is missing. Let's use this technique to discover where the missing values are and investigate why the data might be missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5006e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find missing values, the missing values originate from the cyl column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df70ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Boolean filter for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3660e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame to find missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f3aed",
   "metadata": {},
   "source": [
    "So, why are these observations missing values? This example is great at highlighting the research and investigation that data science often entails. A domain expert, in this case a mechanic or car aficionado might know right away why these cars have missing values. \n",
    "\n",
    "Sometimes understanding our data requires some research. After consulting the [wikipedia](https://en.wikipedia.org/wiki/Mazda_RX-8) page for the `RX-8` and read up about the engine of that car, I found that this car has a *Wankle Rotary Engine* and that the normal concept of *cylinders* does not apply to this special type of engine construction. So, in this case, missing values are perfectly acceptable and reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f817fd97",
   "metadata": {},
   "source": [
    "## What if you just want to get rid of certain observations by label?\n",
    "\n",
    "Sometimes it is easier to specify the observations/columns that you want to exclude rather than specifying what to keep. The `df.drop([<list of cols to drop>])` method will allow us to drop data by label. If wanting to drop specific columns, use the `columns` parameter. If dropping rows, use the `index` parameter.\n",
    "\n",
    "[pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0d8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the mpg and hp column from the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f096dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the MDX from the dataframe\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
